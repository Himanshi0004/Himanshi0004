{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ca6bf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-30T21:40:52.373Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "Record = pd.DataFrame()\n",
    "A_Names = []\n",
    "A_Links = []\n",
    "P_Title = []\n",
    "P_Links = []\n",
    "Year = []\n",
    "\n",
    "def extracting_data(no_of_pages):\n",
    "    page_number = 0\n",
    "    while page_number < no_of_pages:\n",
    "        link_output= 'https://pureportal.coventry.ac.uk/en/organisations/research-centre-for-computational-science-and-mathematical-modell/publications/?page='+str(page_number)\n",
    "        link_response = requests.get(link_output)\n",
    "        soup = BeautifulSoup(link_response.text, \"html.parser\")\n",
    "        \n",
    "        for link in soup.findAll('a', {'rel':['ContributionToBookAnthology',\n",
    "                                              'ContributionToJournal',\n",
    "                                              'ContributionToBookAnthology']}):\n",
    "            \n",
    "            publication_link = link.get('href')\n",
    "            publication_title =link.select_one(\"span\").text\n",
    "            \n",
    "            #queue containing urls\n",
    "            P_Links.append(publication_link)\n",
    "            P_Title.append(publication_title)\n",
    "            \n",
    "            #extracting publication url\n",
    "            publication = requests.get(publication_link)\n",
    "            P_soup = BeautifulSoup(publication.text)\n",
    "            \n",
    "            date = soup.find('span', class_='date')\n",
    "            \n",
    "            A_details = P_soup.find('a', {'class':'link person'}) or int(0)\n",
    "            \n",
    "            #conditions for author details \n",
    "            \n",
    "            if A_details!=0:\n",
    "                A_link = A_details.get('href')\n",
    "                A_name = A_details.select_one(\"span\").text\n",
    "                \n",
    "                A_Names.append(A_name)\n",
    "                A_Links.append(A_link)\n",
    "                \n",
    "                Year.append(date.text)\n",
    "            else:\n",
    "                A_Names.append(\"0\")\n",
    "                A_Links.append(\"0\")\n",
    "                Year.append(date.text)\n",
    "        page_number+=1   \n",
    "    Record={\"publication\": P_Title,\n",
    "            \"publicationUrl\": P_Links,\n",
    "            \"year\": Year,\n",
    "            \"authorName\": A_Names, \n",
    "            \"authorUrl\": A_Links}\n",
    "    Dataframe = pd.DataFrame.from_dict(Record, orient='index')\n",
    "    record_data_transpose = Dataframe.transpose()\n",
    "    return record_data_transpose\n",
    "                \n",
    "Record = extracting_data(20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#printing statements to get record according to publication title ,author_name and year  \n",
    "\n",
    "Publication_Record =  Record['publication']\n",
    "print('publication_title:\\n',Publication_Record )\n",
    "\n",
    "Publication_authorName =  Record['authorName']\n",
    "print('authorName:\\n',Publication_authorName)\n",
    "\n",
    "Publication_year =  Record['year']\n",
    "print('year:\\n',Publication_year)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#importing Natural language Toolkit for stopwards in english \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words_language= set(stopwords.words('english'))\n",
    "print(stop_words_language)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#NLTK tokenization is to be done in this part\n",
    "\n",
    "punctuation_data= '''[\"\\\\\\')\\\\]}]+?(?:\\\\s+|(?=--)|$'''\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "Stemmer= PorterStemmer()\n",
    "preprocessed_document = []\n",
    "for document in Publication_Record:\n",
    "    tokens = word_tokenize(document)\n",
    "    tmp = \"\"\n",
    "    for word in tokens:\n",
    "        if word not in stop_words_language and word not in punctuation_data:\n",
    "            tmp += Stemmer.stem(word) + \" \"\n",
    "    preprocessed_document.append(tmp)\n",
    "     \n",
    "print('Pre-Processed Document:\\n\\n',preprocessed_document)\n",
    "Record['preprocessedTitle']=preprocessed_document\n",
    "print('====================================================================\\n=============================================')\n",
    "print('Record:\\n\\n',Record)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Indexer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "D=[]\n",
    "for eachWord in Record['preprocessedTitle'].str.split():\n",
    "    D.append(eachWord)\n",
    "\n",
    "index_=defaultdict(set)\n",
    "for index, doc in enumerate(D):\n",
    "    for word in doc:\n",
    "        index_[word].add(index)\n",
    "print('INDEXER:\\n',index_)\n",
    "\n",
    "def fetch_Record_result(searchText):\n",
    "    keys = index_.keys()\n",
    "    if searchText in keys:\n",
    "        i = index_[searchText]\n",
    "        for index_Key in i:\n",
    "          return Record.loc[index_Key, :]\n",
    "    \n",
    "\n",
    "\n",
    "# query to run vertical search engine\n",
    "\n",
    "\n",
    "Search_Engine = input(\"|||||WELCOME TO SEARCH ENGINE|||||:\")\n",
    "fetch_Record_result(Search_Engine)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3fd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
